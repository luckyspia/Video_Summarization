## Combining Global and Local Attention with Positional Encoding for Video Summarization

### 0. Abstract
 
 또한, 활용된 attention 메커니즘은 비디오 프레임의 위치를 인코딩하는 구성 요소를 통합한다. 이는 비디오 요약을 생성할 때 매우 중요하다. 두 개의 데이터 셋(SumMe, TVSum)에 대한 실험은 기존의 attention-based methods 방법과 비교하여 제안된 모델의 효과와 다른 state-of-the-art supervised summarization 접근 방식에 비해 경쟁력을 갖고있다. 제안된 주요 구성 요소, 즉 namely the use of global와 협력하여 local multi-head attention의 사용에 초점을 맞춘 연구는 요약 성능 향상에 상대적 기여를 했다.

Keywords-video summarization; self-attention; multi-head attention; positional encoding; supervised learning



### 1. Introduction

- 최근 컨탠츠 생성과 공유 기술 발전으로 비디오가 가장 보편적으로 선호되는 매체가 되었다. 사람들은 비디오 녹화 및 온라인 공유 기능(ex 스마트폰, 태블릿, 웨어러블 카메라)에 점점 더 많이 관여하고 있다. 동시에 SNS(ex: 페북, 인스타, 트위터, 틱톡)와 영상 공유 플랫폼(ex: 유튜브, Vimeo, Dailymotion)을 아마추어와 전문 사용자 모두 사용하고 있다. 이러한 기술 환경은 웹을 통한 비디오의 엄청난 성장을 자극했으며 사용자가 비디오의 컬렉션 내에서 탐색하고 원하는 비디오 컨텐츠를 빠르게 검색할 수 있도록 하는 기술의 필요성을 강조했다. 자동 비디오 요약을 위해 전체 길이 비디오의 중요한 부 분을 전달하는 간결한 시놉시스를 생성할 수 있다. 이를 기반으로 시청자는 전체 콘텐츠를 보지 않고도 전체 스토리를 빠르 게 살펴볼 수 있다.
- 비디오 요약을 자동화하기 위해 몇 가지 접근 방식이 제안되었으며 심층 네트워크 아키텍처를 기반으로 하는 방법은 해당 분 야의 현재 기술 상태를 나타낸다. 문헌에 대한 최근 연구에 따르면 대부분의 접근 방식은 RNN을 사용하여 비디오 프레임 간의 시간적 종속성을 모델링하고 프레임의 중요도를 추정하는 방법을 학습한다(ex: [2] - [15]). 그러나 비디오 요약을 위한 RNN 및 그 변형(대부분 LSTM 및 GRU)의 사용은 몇 가지 약점을 보여준다. 이는 네트워크에서 순방향 및 역방향 신호가 통과해야 하는 긴 경로와 관련이 있으며, 이는 장거리 종속성을 모델링하는 네트워크의 능력에 부정적인 영향을 미치게 된다.
- 앞서 언급한 단점을 극복하기 위해 일부 연구는 완전히 다른 접근 방식을 따른다. RNN을 사용하는 대신 학습 가능한 self-attention 메커니즘을 사용하여 프레임의 종속성을 모델링한다. 그럼에도 불구하고 이러한 메커니즘은 i) 비디오 프레 임의 쌍별 유사성에만 초점을 맞추고 ii) 전체 프레임 시퀀스에 적용됩니다. 전자의 관찰 은 기존의 self-attention 기반 요약 접근 방식이 비디오 요약을 생성할 때 가장 중요 한 비디오 프레임의 시간적 순서를 무시한다는 점을 강조한다. 후자의 관찰은 긴 비디 오의 경우 성능 저하의 위험을 지적한다. 에서 논의된 바와 같이 시간적으로 먼 장 면의 프레임이 로컬 장면보다 관련성이 낮을 가능성이 높지만 전 세계의 관심이 여전히 이를 탐색해야 하기 때문입니다. 이는 주의 값의 분산을 증가시켜 프레임의 중요도 추정 정확도에 부정적인 영향을 미친다.
- 위에서 논의한 기존 self-attention-based summarization 방법의 한계를 해결하기 위해 PGL-SUM이라는 새로운 지도 접근 방식을 제안한다. 이 접근 방식은 절대 위치 인코딩 구성요소를 다음을 모델링하는 한 쌍의 다중 헤드 self-attention 메커니즘에 통합한다. 그만큼 다른 세분성에서 프레임의 종속성에 사용된 attention 메커니즘을 기반으로 개발된 네트워크 아키텍처는 전체 프레임 시퀀스를 고려하고 더 작은 부분에 집중함으 로써 비디오의 가장 중요한 부분을 식별하는 방법을 배울 수 있다. 이 지식 을 바탕으로 비디오 프레임의 시간적 순서를 모델링하는 구성 요소를 통합함 으로써 제안된 PGL-SUM 모델은 간결하고 시간적으로 일관된 비디오 요약 을 생성할 수 있다. 
- 제안점으로
  -  비디오 요약 작업을 처리하기 위해 self-attention 메커니즘의 일부로 절대 위치 인코딩 사용을 소개
  - 다른 연구원의 자료에서 프레임 종속성의 더 나은 모델링을 학습하기 위해 absolute positional encoding 구성 요소를 전역 및 로컬 multi-head attention 메커니즘에 포함하는 새로운 아키텍처를 제안



### 2. Related Work

- 비디오 요약을 자동화하기 위해 다양한 접근 방식(매개채)이 deep network architectures를 활용하는 방법으로 표현된다. 공간을 위해 이 섹션에서는 제안된 방법과 가장 밀접하게 관련된 attention 메커니즘을 활용하는 접근 방식에 주로 초점을 맞춘 의도한 비디오 요약에 대해 관련 문헌을 간략하게 제시한다.
- 비디오 요약을 위한 처음에 접근하는 방식 중 하나는 프레임 간의 variable-range temporal을 모델링하고 ground-truth annotations에 따라 프레임의 중요성을 추정하는 방법 을 배우는 것이다. 이를 위해 일부 방법은 RNN 또는 Fully  Convolutional Sequence Networks의 구조를 사용한다. 다른 연구들은 다음과 관련된 문제들을 다룰려고 시도를 한다. RNN의 제한된 용량 및 추가 메모리 사용과 관련된 문제를 해결하고자 외부 저장소의 형태로 추가 메모리를 사용하거나, 여러 LSTM과 메모리 레이어를 계층적으로 쌓아 추가 메모리를 사용하려한다. 일부 알고리즘은 고전적 또는 sequence-to-sequence RNN 기반 아키텍처에 맞춤형 attention 메커니즘을 도입하여 사용자 관심의 발전를 모델링하는 것을 목표로 한다.
- Lebron Casas et al. 프레임의 temporal dependence을 모델링하고 중요도를 추정 하거나 다양한 비디오 요약을 생성하는 방법을 학습하기 위한 새로운 프레임 표현을 형성하기 위해 LSTM 기반 주의 계층을 포함하여 에서 아키텍처를 확장한다. Ji et al. 비디오 요약을  sequence-to-sequence 학습 문제로 공식화 하고 attention 계층을 LSTM-based encoder-decoder network에 통합한다. attention 계층을 통합시킬때 인코더의 출력과 디코더의 보이지 않는 상태까지 가져오고 attention 값으로 벡터를 계산하며, 이는 이후에 비디오 디코딩 프로세스에 영향을 준다. 다음 작업 에서 Ji et al. 은 디코더의 출력을 평가하는 의미론적 보존 embedding network를 통합하는 모델 확장을 도입 맞춤형  semantic preserving loss를 사용하여 비디오의  semantic preserving에 관한 것이다.
- 한 단계 더 나아가 몇 가지 비디오 요약 방법은 비디오의 시공간 구조를 모델링하여 프레임/단위의 중요성을 학습한다. 이를 위해 몇 가지 작업에서 는 일반적인 CNN 기반 심층 표현과 함께  convolutional LSTM을 사용하거나 학습 가능한 3D-CNN-based deep representations을 합친다. 또 다른 접근 법은 원시 프레임과 그 시각적 흐름 맵을 CNN으로 처리하여 공간 및 시간 정보를 추출하고 레이블 분포 학습 프로세스를 기반으로 프레임의 중요도를 학습한다. 다른 전략에 따라 [13]의 방법은 CNN과 GRU를 결합하여 각 프 레임의 활동 수준과 중요도를 추정하는 데 사용되는 시공간적 특징 벡터를 형성한다. 마지막으로 Huang et al. 시공간 데이터 추출을 위해 신경망을 훈련하고 추출된 정보를 사용하여 모션 곡선을 만들고 비디오 캡처본을 식별한다. 그런 다음 다른 연구본을 기반으로 self-attention 모델이 캡처본내 중요도를 추정하고 비디오의 중요한 프레임/단위를 선택하여 정적/동적 비디오 요약을 구성하는 방법을 학습한다.
- 기계 생성 요약과 실제 정보 요약 사이의 거리를 최소화하기 위해 다른 전략을 채택하는 몇 가지 방법은  Generative Adversarial Networks를 사용한다. 그들의 목표는 사용자 생성 요약에서 기계를 구별할 때 훈련 가능한 판별자를 속이기 위해 요약자를 훈련하는 것이다.
- 마지막으로 몇 가지 접근 방식은 Transformer Network의 self-attention 메커니즘의 변형을 사용하여 프레임의 종속성을 모델링하는 것을 목표로 한다. 이 방향에 대한 첫 번째 접근 방식은 프레임의 중요도 점수 회귀를 위한  two-layer fully connected network와 a soft self-attention 메커니즘을 결합한다. Liu et al. 초기에 일련의 shot-level candidate key-frames을 정의한 다음 multi-head attention model을 사용하여 후보의 중요성을 추가로 평가하고 요약을 구성하는 키 프레임을 선택하는 계층적 접근 방식을 설명한다.
- Li et al. 계산된 attention 값을 사용하고 요약의 시각적 콘텐츠의 다양성을 증가시키려는 처리 단계를 도입하여 일반적인 self-attention 메커니즘의 교육 파이프라인을 확장한다. 추정된 attention 값(프레임의 다양성에 대한 정보를 통합한 후)은 프레임의 중요도를 추정하고 연구록에서부터 요약을 통해 학습하는데 사용된다. Ghauri et al. [26]은 비디오 콘텐츠의 추가 표현을 사용하는 아키 텍처의 변형을 제안한다. 전형적인 CNN-based features(ImageNet에서 훈련된 GoogleNet [27]의 pool5 레이어에서 얻음) 외에도 Ghauri et al. Kinetics 에 대해 훈련된 Inflated 3D ConvNet [28] 모델을 사용하여 모션 관련 기능 세트를 추출한다. 각각의 다른 기능 세트는 self-attention 메커니즘에 제공 되고 이러한 메커니즘의 출력은 비디오 프레임을 표현하기 위한 common embedding space을 형성하기 위해 융합된다. 획득한 자료는 마지막으로 프레임의 중요도를 추정하는 방법을 배우는데 사용된다.
- 제안된 접근 방식은 self-attention 메커니즘에 의존하는 이전 단락의 방법과 가장 밀접하게 관련되어 있습니다. 그럼에도 불구하고 전체 프레임 시퀀스를 고려한 후 프레임의 종속성을 모델링하는 이러한 모든 방법과 달리 개발된 PGL-SUM 모델은 전역 및 로컬 multi-head attention 메커니즘의 도움으로 서로 다른 세분성에서 프레임의 종속성을 캡처합니다. 더욱이, 비디오의 순차적인 특성을 완 전히 무시하는 이러한 방법과 대조적으로, 우리의 접근 방식은 프레임을 추정 할 때 결정적인 정보 유형인 프레임의 시간적 위치를 인코딩하는 구성 요소를 포함하여 활용되는 주의 메커니즘을 향상시킵니다. 중요성. 앞서 언급한 차이 점은 섹션 IV에 보고된 바와 같이 기존 자기 주의 기반 접근 방식의 관련 제한 을 목표로 하고 고급 요약 성능으로 이어집니다.







## 4. EXPERIMENTS

- 데이터셋 및 평가 접근 방식
- PGL-SUM 모델 성능을 평가하기 위해 두 가지 데이터 세트를 사용했다. SumMe 데이터에는 1인칭 및 3인칭 관점에서 다루는 25개의 비디오(1~6분)가 포함되어 있다. 각각의 비디오는 key-fragments 형태로 여러(15-18) 주석과 연결되어있다. 또한 지도학습을 진행하기 위해 각 비디오에 대해 프레임 레벨 중요도 점수(프레임당 key-fragment 사용자 요약을 평균화하여 계산) 형태의 단일 실측 요약 제공된다. TVSUM은 TRECVid MED dataset의 10개 범주에서 50개의 비디오(1-11분)로 구성된다. 각 비디오는 20명의 사용자가 프레임별로 중요도 점수를 평가하며, 단일 실측 정보 요약(모든 사용자의 점수를 평균하여 계산)도 사용할 수 있다.
- 평가 접근 방식
- 최신 접근 방식과 비교를 위해 우리는 [2]에서 제안된 keyfragment-based evaluation protocol을 채택한다. 기계학습과 사용자가 정의한 값의 유사성은 F-score를 사용하여 중첩 계산하여 추정된다. 따라서 비디오가 주어지면 추출된 비디오 요약본과 사용자가 추출한 요약본을 비교하여 각 쌍에 대한 F-score를 계산한다. 그 후 계산된 F-score(TVSum의 경우)를 평균화하거나 최대값을 유지하고 이 비디오에 대한 최정 F-score를 도출한다. 테스트 비디오들에 대해 계산된 F-score를 평균화 하여 method’s 성능에 대한 최종 결과를 형성한다.



### 5.CONCLUSION

- 본 연구에서 지도학습 비디오 요약을 위한 새로운 네트워크 아키텍처를 제안했는데, 이는 i) 장거리 프레임 모델링, ii) 훈련 프로세스의 병렬화 능력(기존 RNN 기반 방법의 두 가지 단점),  iii) 기존 접근 방식의 한계를 극복하는 지도학습 비디오 요약을 위해 프레임간의 시간적 의존성이 모델링되는 기존의 self-attention-based methods의 약점에 대해 제안 했다.  개발된 PGL-SUM 모델은 비디오 프레임의 시간 위치를 인코딩하기 위한 구성요소를 통합하는 multi-head attention mechanisms을 사용한다. 이러한 메커니즘 중 하나는 전체 프레임 시퀀스에 따라 프레임의 시간 의존성을 모델링하는 것을 목표로 하며, 나머지 메커니즘은 비디오의 더 작은 부분에 초점을 맞춤으로써 이러한 시간 의존성의 모델링을 발견하려 한다. 본 연구는 absolute positional encoding component 요소와 결합된 global and local multi-head attention을 사용하여 제안했다. 데이터 세트에 대한 실험은 PGL-SUM 모델이 self-attention 메커니즘에 의존하는 기존 방식에 비해 우수한 성능의 모델임을 보여주었고, 다른 state-of-theart 지도학습 접근 방식에 대한 경쟁력을 보여주었다.